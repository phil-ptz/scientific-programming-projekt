{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier\n",
        "\n",
        "Dieses Notebook ist ein Beispiel, wie man die gespeicherten Gewichte des Modells, welche beim Training erstellt wurden, l채dt und auf einem Datensatz testet."
      ],
      "metadata": {
        "id": "RDF9qsioNPc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "- Torch - Laden und nutzen des Modells \\\n",
        "- Matplotlib - Anzeigen der Bilder \\\n",
        "- OS - Dateipfadverwaltung \\\n",
        "- Random - Zuf채llige Auswahl der Bilder"
      ],
      "metadata": {
        "id": "-Va-0HHBN2DZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GajsQGpffZuc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datensatz laden\n",
        "\n",
        "Den Datensatz laden wir aus Google Drive, da es mit Colab am besten funktioniert."
      ],
      "metadata": {
        "id": "8AfGtE6hOl4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/Dataset/data.zip /content\n",
        "!unzip /content/data.zip"
      ],
      "metadata": {
        "id": "nTN9f_xHnuyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modell laden\n",
        "\n",
        "Hier nochmal die gleiche Modell-Architektur wie im Training. Die Gewichte werden aus der pth-Datei, welche beim Training erstellt wurde geladen. Danach ist das Modell bereit zum Klassifizieren."
      ],
      "metadata": {
        "id": "-5jIYKVWO2rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 256"
      ],
      "metadata": {
        "id": "jfT9FQW4hFSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modell Klasse\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    TinyVGG:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=hidden_units * (IMAGE_SIZE//4) * (IMAGE_SIZE//4),\n",
        "                    out_features=output_shape)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dl6QCOQHg9cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gewichte laden\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CNNModel(input_shape=3, hidden_units=32, output_shape=2).to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Dataset/saves/model_weights_95.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "mEZgYQfwfg88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ergebnis ausgeben\n",
        "\n",
        "Im letzten Teil werden Bilder aus dem Datensatz zuf채llig ausgew채hlt und klassifiziert. Das Ergebnis wird dann grafisch dargestellt."
      ],
      "metadata": {
        "id": "3_9-YPrjP84c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verzeichnisse\n",
        "base_dir = \"/content/data\"\n",
        "classes = [\"fake\", \"real\"]\n",
        "num_images_per_class = 5\n",
        "\n",
        "# Transformation Training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Bilder sammeln\n",
        "selected_images = []\n",
        "for label in classes:\n",
        "    folder_path = os.path.join(base_dir, label)\n",
        "    images = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    selected = random.sample(images, num_images_per_class)\n",
        "    selected_images.extend([(img, label) for img in selected])"
      ],
      "metadata": {
        "id": "Fx001GMtoOd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilder mit Label und Vorhersage ausgeben\n",
        "for img_path, true_label in selected_images:\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        predicted_class = torch.argmax(output, dim=1).item()\n",
        "        predicted_label = classes[predicted_class]\n",
        "\n",
        "    # Anzeige mit Matplotlib\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Label: {true_label}\\nVorhersage: {predicted_label}\", fontsize=15)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sNrFxIHPjfxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}